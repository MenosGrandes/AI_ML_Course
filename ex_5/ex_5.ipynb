{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9bf14c-8a3e-4bfa-babd-60af7f707ba2",
   "metadata": {},
   "source": [
    "Proceed with the dataset and find the best classifier predicting survivability.\n",
    "*   Use all the classifiers covered so far. Provide automatic mechanism to compare performance of various models.\n",
    "*   If you would like to look for some other classifiers in sklearn, then it is OK.\n",
    "*   Use pipelines if necessary, especially if you decide to use normalization/standardization or PCA.\n",
    "*   For each model, try to find the best hyperparameters.\n",
    "*   For various results of cross-validation present ROCs and PRCs.\n",
    "*   If you lack data (`NaN` etc.), do not skip the samples. Instead, impute them: the best option is to find similar samples (on the basis of other features) and then calculate the missing data by taking mean value. You can apply some basic form of clustering. KNNs are also the option.\n",
    "\n",
    "**This homework is obligatory. Just do as much time lets you. Even a small analysis will be welcome. Please send colab link to krusek@agh.edu.pl before 17.04.2024. Give permission to edit!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a96ab4-9f20-4dd0-9da1-d73d989132e8",
   "metadata": {},
   "source": [
    "## https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html\n",
    "0. Survived Indicator\n",
    "1. Passenger Class\n",
    "2. Name\n",
    "3. Sex\n",
    "4. Age\n",
    "5. Siblings Aboard\n",
    "6. Parents Aboard\n",
    "7. Fare paid in Â£s\n",
    "\n",
    "\n",
    "- survival - Survival (0 = No; 1 = Yes)\n",
    "- class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- name - Name\n",
    "- sex - Sex\n",
    "- age - Age\n",
    "- sibsp - Number of Siblings/Spouses Aboard\n",
    "- parch - Number of Parents/Children Aboard\n",
    "- ticket - Ticket Number\n",
    "- fare - Passenger Fare\n",
    "- cabin - Cabin\n",
    "- embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- boat - Lifeboat (if survived)\n",
    "- body - Body number (if did not survive and body was recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189e1b35-93ed-4424-98c1-694c2997c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys;\n",
    "#define Seaborn color palette to use\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from itertools import zip_longest\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b802e270-b7da-4857-b3e0-1245386a1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = platform.python_version_tuple();\n",
    "if float(v[1]) < 10:\n",
    "    raise Exception(\"MUST USE Python 3.10 to use MATCH expression!\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "from enum import Enum, unique\n",
    "\n",
    "@unique\n",
    "class PDataType(Enum):\n",
    "    NUMERICAL = 1\n",
    "    CATHEGORICAL = 2\n",
    "\n",
    "def remove_distinct_value_features(df):\n",
    "    return [e for e in df.columns if df[e].nunique() == 1]\n",
    "\n",
    "def get_data_type(df, type):\n",
    "    match type:\n",
    "        case PDataType.NUMERICAL:\n",
    "            return df.select_dtypes(np.number);\n",
    "        case PDataType.CATHEGORICAL:\n",
    "            return df.select_dtypes(include='object');\n",
    "\n",
    "#select all cathegorigal data where the first value is more than percent%?\n",
    "def get_cathegorical_data_by_percent(df, percent):\n",
    "    col_names = get_data_type(df,PDataType.CATHEGORICAL)\n",
    "    to_return = []\n",
    "    for col_name in col_names:\n",
    "        unique_v_df = (df[col_name].value_counts()).to_frame()\n",
    "        unique_v_df['percent'] = (unique_v_df/unique_v_df.sum()*100)\n",
    "        if unique_v_df.iloc[0].percent > percent:\n",
    "            to_return.append(col_name);\n",
    "    return to_return\n",
    "    \n",
    "def fill_empty_data_with(df, type, filler):\n",
    "    col_names = get_data_type(df,type)\n",
    "    for c in col_names:\n",
    "        test_data_csv[c] = test_data_csv[c].fillna(filler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e8784ba-4419-45a9-b52f-9ee4eb3770a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_NOT_PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e85079-01c1-4d7b-b69e-eb0f02bef73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_pie_for_unique_category(df,col_name_x, ax):\n",
    "    if not DO_NOT_PLOT:\n",
    "        colors = sns.color_palette('pastel')\n",
    "        unique_v_df = (df[col_name_x].value_counts()).to_frame()\n",
    "        unique_v_df['percent'] = (unique_v_df/unique_v_df.sum()*100)\n",
    "        unique_v_df.plot.pie(y='count', use_index=True,autopct='%0.2f%%', title = f\"{col_name_x}\", ax = ax)\n",
    "\n",
    "\n",
    "def plot_hist_for_unique_category(df,col_name_x,col_name_y):\n",
    "    if not DO_NOT_PLOT:\n",
    "        unique_v_df = (df[col_name_x].value_counts()).to_frame()\n",
    "        unique_v_df['percent'] = (unique_v_df/unique_v_df.sum()*100)\n",
    "        fig, axs = plt.subplots(nrows=len(unique_v_df), figsize=(16,10))\n",
    "        i = 0;\n",
    "        for index, row in unique_v_df.iterrows():\n",
    "            value_percent = row.iloc[1];\n",
    "            value = row.iloc[0];\n",
    "            name = index;\n",
    "            sns.histplot(data=df.loc[df[col_name_x] == name], x=col_name_y, ax = axs[i],bins=100, label =f'{col_name_x} {name} : {value} | {value_percent:.2f}%')\n",
    "            axs[i].set_xlim(df[col_name_y].min(), df[col_name_y].max())\n",
    "            axs[i].legend()\n",
    "            i+=1\n",
    "        fig.suptitle(f\"{col_name_x} on {col_name_y}\")\n",
    "        plt.show()\n",
    "        \n",
    "def plot_hist_for_stat(df,col_name_x, stat = 'count'):\n",
    "    if not DO_NOT_PLOT:\n",
    "        sns.histplot(data=df, x=col_name_x, stat = stat)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "                     \n",
    "    \n",
    "def plot_unique_category(df,col_name_x,col_name_y):\n",
    "    if not DO_NOT_PLOT:\n",
    "        plot_hist_for_unique_category(df,col_name_x,col_name_y)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10,10))\n",
    "        fig.tight_layout()\n",
    "        plot_pie_for_unique_category(df,col_name_x,axs[0])\n",
    "        sns.boxenplot(data=df, x=col_name_x, y=col_name_y, ax = axs[1])\n",
    "        plt.show()\n",
    "    \n",
    "def plot_hist_for_unique_category_array(df,col_names_x,col_name_y):\n",
    "    if not DO_NOT_PLOT:\n",
    "        for col_name_x in col_names_x:\n",
    "            plot_hist_for_unique_category(df,col_name_x,col_name_y)\n",
    "            plt.show()\n",
    "\n",
    "#RAVEL returns flatted array, depricated. use to_numpy\n",
    "def plot_pie_for_unique_category_array(df,col_names_x):\n",
    "    if not DO_NOT_PLOT:\n",
    "        n_rows, n_cols = ceil(len(col_names_x) / 3), 3\n",
    "        fig, axs = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(20, 80))\n",
    "        for col_name_x,ax in zip_longest(col_names_x,axs.ravel()):\n",
    "            if col_name_x is not None:\n",
    "                colors = sns.color_palette('pastel')\n",
    "                unique_v_df = (df[col_name_x].value_counts()).to_frame()\n",
    "                unique_v_df['percent'] = (unique_v_df/unique_v_df.sum()*100)\n",
    "                unique_v_df.plot.pie(y='count', use_index=True,autopct='%0.2f%%', title = f\"{col_name_x}\",ax=ax )\n",
    "            else:\n",
    "                fig.delaxes(ax)\n",
    "        plt.draw()\n",
    "        plt.tight_layout()\n",
    "    \n",
    "\n",
    "def plot_correlation_for(df, col_name, n):\n",
    "    corr = df.corr(numeric_only=True)[col_name].sort_values(ascending=False)\n",
    "    top_corr = corr[1:n]\n",
    "    selected_features = list(top_corr.index) + [col_name]\n",
    "    correlation_matrix = df[selected_features].corr()\n",
    "    mask = np.triu(correlation_matrix)\n",
    "    if not DO_NOT_PLOT:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", linewidths=.5, fmt=\".2f\", vmin=-1, vmax=1,mask=mask)\n",
    "        plt.title(f\"Top of correlation with [{col_name}]\", fontsize=16)\n",
    "        plt.show()\n",
    "    return top_corr\n",
    "\n",
    "def plot_overall_correlation_for(df,target_cols,n_count):\n",
    "    df_no_target = df.copy().drop(columns = target_cols)\n",
    "    top_correlation = df_no_target.corr().unstack().sort_values(ascending = False).drop_duplicates()[1:n_count]\n",
    "    top_correlation.plot.bar(grid = True)\n",
    "    return  top_correlation\n",
    "def scikit_model_vis(y_valid, y_pred):\n",
    "    if not DO_NOT_PLOT:\n",
    "        plt.figure()\n",
    "        plt.scatter(y_valid, y_pred)\n",
    "        plt.xlabel('ground truth (y_valid)')\n",
    "        plt.ylabel('predict (y_pred)')\n",
    "        plt.show()\n",
    "\n",
    "    print(f'MAE: {metrics.mean_absolute_error(y_valid, y_pred):.2f}')\n",
    "    print(f'MSE: {metrics.mean_squared_error(y_valid, y_pred):.2f}')\n",
    "    print(f'R2: {metrics.r2_score(y_valid, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3712ab0f-d685-46db-bb94-523418a54ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass survived                            name     sex      age  sibsp  \\\n",
       "0       1        1   Allen, Miss. Elisabeth Walton  female  29.0000      0   \n",
       "1       1        1  Allison, Master. Hudson Trevor    male   0.9167      1   \n",
       "2       1        0    Allison, Miss. Helen Loraine  female   2.0000      1   \n",
       "\n",
       "   parch  ticket      fare    cabin embarked boat  body  \\\n",
       "0      0   24160  211.3375       B5        S    2   NaN   \n",
       "1      2  113781  151.5500  C22 C26        S   11   NaN   \n",
       "2      2  113781  151.5500  C22 C26        S  NaN   NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@markdown You know this data, but so far you had the opportunity to work with classification on it\n",
    "\n",
    "#titanic = pd.read_csv('https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/titanic.csv')\n",
    "df = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
    "df = df['frame']\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e76fa0fb-5dea-4a97-ba74-e20f3e20ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   pclass     1309 non-null   int64   \n",
      " 1   survived   1309 non-null   category\n",
      " 2   name       1309 non-null   object  \n",
      " 3   sex        1309 non-null   category\n",
      " 4   age        1046 non-null   float64 \n",
      " 5   sibsp      1309 non-null   int64   \n",
      " 6   parch      1309 non-null   int64   \n",
      " 7   ticket     1309 non-null   object  \n",
      " 8   fare       1308 non-null   float64 \n",
      " 9   cabin      295 non-null    object  \n",
      " 10  embarked   1307 non-null   category\n",
      " 11  boat       486 non-null    object  \n",
      " 12  body       121 non-null    float64 \n",
      " 13  home.dest  745 non-null    object  \n",
      "dtypes: category(3), float64(3), int64(3), object(5)\n",
      "memory usage: 116.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a84f39-f774-4e20-bc2f-a8ebd9c9f74a",
   "metadata": {},
   "source": [
    "## Convert some data, cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a69069f-2ebb-4af6-b1a8-bcb4222f1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass          0\n",
      "survived        0\n",
      "name            0\n",
      "sex             0\n",
      "age           263\n",
      "sibsp           0\n",
      "parch           0\n",
      "ticket          0\n",
      "fare            1\n",
      "cabin        1014\n",
      "embarked        2\n",
      "boat          823\n",
      "body         1188\n",
      "home.dest     564\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9daa1a4e-cf2f-4def-a070-4793dfc96cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msibsp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msibsp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:145\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "\n",
    "df['age'] = df['age'].astype('int8')\n",
    "df['sibsp'] = df['sibsp'].astype('int8')\n",
    "df['Sex'] = df['Sex'].map({'male': 0,'female': 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab238ab0-fdc9-478c-ab40-cf531841ecdf",
   "metadata": {},
   "source": [
    "## PClass to OneHotEncoder! Its much clearer what is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56f6ba-926d-44fb-bec1-c554e548b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df[['Pclass']]).toarray()).add_prefix('class_')\n",
    "df = df.join(enc_df)\n",
    "df = df.drop(columns = ['Pclass'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535269f5-c340-4bef-8c09-e31c54d6eeed",
   "metadata": {},
   "source": [
    "There are items with 0 fee, which is weird\n",
    "how Fare can be 0? Only man. Multiple ages, and multiple Pclass\n",
    "maybe they are workers? Or they are sponsors? No.. sponsors would get more family, I think\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8883d-ef28-4c95-b190-350c95ed7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Fare'].describe())\n",
    "zero_fee = df[df['Fare'] == 0]\n",
    "\n",
    "def search_string(s, search):\n",
    "    return search in str(s).lower()\n",
    "\n",
    "for Name in zero_fee['Name']:\n",
    "    _name_list = list(Name.split(\" \"))\n",
    "    length = len(_name_list)\n",
    "    sure_name = _name_list[length-1].lower()\n",
    "    mask = df.apply(lambda x: x.map(lambda s: search_string(s, sure_name)))\n",
    "    filtered_df = df.loc[mask.any(axis=1)]\n",
    "    print(sure_name)\n",
    "    print(filtered_df['Name'])\n",
    "    print(\"^\"*10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435680a6-5ad9-4c7e-85f5-a0af0e56acc0",
   "metadata": {},
   "source": [
    "## 0 fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41850e2-3cac-4ed7-a651-2302e9a2ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "_indexes  = zero_fee.index.to_numpy();\n",
    "_len_0 = len(_indexes)\n",
    "print(f'Percent of people with 0 Fee is = {(_len_0 * 100) / df.shape[0]} %')\n",
    "df = df.drop(index=_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709dd6f-478c-4a08-9aeb-7934df7575ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_values('Fare', ascending = False).head(80)[['Fare','class_0','class_1','class_2']])\n",
    "print(df.sort_values('Fare').head(80)[['Fare','class_0','class_1','class_2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14fc64-df93-4560-9937-ad46a40583e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa82c81-ca2e-490b-91c7-61e0bc288965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop name, for now\n",
    "no_name_DF = df.drop(columns = ['Name'])\n",
    "plot_overall_correlation_for(no_name_DF,'Survived',5)\n",
    "plot_correlation_for(no_name_DF, 'Survived',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab0236-936e-4ae2-a3d3-2ff5080b4e41",
   "metadata": {},
   "source": [
    "## Fare and PClass have high correlation. So... look it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b24e38-ce89-4206-b595-0f859b7873b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclasses = ['class_0','class_1','class_2']\n",
    "fig, axs = plt.subplots(1, len(Pclasses), figsize=(20,10))\n",
    "for i,Pclass in enumerate(Pclasses):\n",
    "    sns.histplot(no_name_DF[no_name_DF[Pclass] == 1]['Fare'], ax = axs[i], label = f'Pclass =[{Pclass}]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2a207-dc8b-4da5-bb93-e2fb3dd9e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_for(no_name_DF, 'Sex',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecccac-c0c2-46af-9a49-9cab0b5c09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between sex and survival. In Percent\n",
    "women = no_name_DF.loc[no_name_DF.Sex == 1][\"Survived\"]\n",
    "rate_women = (sum(women)/len(women) ) * 100\n",
    "#print(f\"woman count : {no_name_DF.loc[no_name_DF.Sex == 1].value_counts():,.2f} %\")\n",
    "allSexes = no_name_DF['Sex'].value_counts();\n",
    "print(f\"Man on Titanic {allSexes[0]}\")\n",
    "print(f\"Woman on Titanic {allSexes[1]}\")\n",
    "print(f\"Woman/Man ratio on Titanic {allSexes[1]/allSexes[0]}\")\n",
    "\n",
    "print(f\"Survival rate woman : {rate_women:,.2f} %\")\n",
    "\n",
    "man = no_name_DF.loc[no_name_DF.Sex == 0][\"Survived\"]\n",
    "rate_men = (sum(man)/len(man))*100\n",
    "print(f\"Survival rate man : {rate_men:,.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f33ee-7ec2-4717-833b-c69bbb74edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fee_boxplot(_df):\n",
    "    _0 = _df.loc[_df['class_0'] == 1, 'Fare'].values\n",
    "    _1 = _df.loc[_df['class_1'] == 1, 'Fare'].values\n",
    "    _2 = _df.loc[_df['class_2'] == 1, 'Fare'].values\n",
    "    plt.boxplot([_0,_1,_2], labels = [\"class_0\",\"class_1\",\"class_2\"])\n",
    "print_fee_boxplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d8d63-99cf-4b6b-b9f2-4114a6e8c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea75f7a-f9f2-4ef5-820e-a490941f573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_LogisticRegression(X,y):   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n",
    "    log_reg = LogisticRegression(max_iter=1000) ## I have some error in here...\n",
    "    log_reg.fit(X_train.values, y_train) # Provide only values without headers!\n",
    "    print(f\"log_reg score = {log_reg.score(X_test.values, y_test)}\")\n",
    "    return (X_train, X_test, y_train, y_test, log_reg) #Return values only\n",
    "\n",
    "def do_prediction(_df,_targetColumnString):\n",
    "    print(\"!-\"*10)\n",
    "    X = _df.drop(_targetColumnString, axis = 1)\n",
    "    y = _df[_targetColumnString]\n",
    "    X_train, X_test, y_train, y_test, log_reg = train_LogisticRegression(X,y)\n",
    "    print(f\"cross_val_score = {cross_val_score(log_reg, X, y, cv=5).mean()}\")\n",
    "    y_predicted = log_reg.predict(X_test.values)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(log_reg, X_test.values, y_test)\n",
    "    disp.plot()\n",
    "    log_regrression_curve = RocCurveDisplay.from_estimator(log_reg, X_test.values, y_test)\n",
    "    print(\"!-\"*10)\n",
    "    return log_reg;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b2062-c83d-4409-aa53-f02358bd0fad",
   "metadata": {},
   "source": [
    "# Some random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f1e96-19d2-4f5e-b4e5-4e1c76b4ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_passenger(sex,age,sib_sp_abo,par_chil_abo, fare, classType):\n",
    "    return ([[sex,age,sib_sp_abo,par_chil_abo, fare, classType == 0, classType == 1, classType == 2]],\n",
    "            f\" sex=[{sex}],age=[{age}],sib_sp_abo=[{sib_sp_abo}],par_chil_abo=[{par_chil_abo}], fare=[{fare}], classType=[{classType}]\")\n",
    "\n",
    "passengers = [create_passenger(1,30,0,0,21,0),\n",
    " create_passenger(0,30,0,0,21,0),\n",
    " create_passenger(1,30,0,0,21,1),\n",
    " create_passenger(0,30,0,0,21,1),\n",
    " create_passenger(1,30,0,0,21,2),\n",
    " create_passenger(0,30,0,0,21,2),\n",
    "create_passenger(1,30,0,0,76,0),\n",
    "create_passenger(0,30,0,0,76,0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd054a21-c842-4c82-9f08-87616d474a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_passengers(_passengers, predictor):\n",
    "    print(10*'^-')\n",
    "    for passenger_v, passenger_s in _passengers:\n",
    "        predictor.predict(passenger_v)[0]\n",
    "        probability = predictor.predict_proba(passenger_v)[0][1]\n",
    "        print(f'Parameters: {passenger_s}')\n",
    "        print(f'\\tProbability of survival: {probability:.1%}')\n",
    "    print(10*'@-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef80acd-e1e7-4ad5-a4f6-443c0d863338",
   "metadata": {},
   "source": [
    "# Try to remove those highest values of fee and see what will happend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78741fb-870b-43f3-b257-17de628970a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_0 = df.loc[df['class_0'] == 1, 'Fare'].quantile(0.75, interpolation='midpoint')\n",
    "_1 = df.loc[df['class_1'] == 1, 'Fare'].quantile(0.75, interpolation='midpoint')\n",
    "_2 = df.loc[df['class_2'] == 1, 'Fare'].quantile(0.65, interpolation='midpoint')\n",
    "\n",
    "df_removed_fee = df.copy()\n",
    "df_removed_fee.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "df_removed_fee.drop(df_removed_fee[(df_removed_fee['class_0'] == 1) & (df_removed_fee['Fare'] > _0)].index, inplace=True)\n",
    "df_removed_fee.drop(df_removed_fee[(df_removed_fee['class_1'] == 1) & (df_removed_fee['Fare'] > _1)].index, inplace=True)\n",
    "df_removed_fee.drop(df_removed_fee[(df_removed_fee['class_2'] == 1) & (df_removed_fee['Fare'] > _2)].index, inplace=True)\n",
    "\n",
    "print_fee_boxplot(df_removed_fee)\n",
    "plt.show()\n",
    "print_fee_boxplot(df)\n",
    "def print_fee_boxplot_2(_df):\n",
    "    _2 = _df.loc[_df['class_2'] == 1, 'Fare'].values\n",
    "    plt.boxplot([_2], labels = [\"class_2\"])\n",
    "plt.show()\n",
    "print_fee_boxplot_2(df_removed_fee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db74f0-9474-4ce4-b272-bc88dc44fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed_0_fee = df_removed_fee.copy()\n",
    "\n",
    "df_removed_0_fee.drop(df_removed_fee[(df_removed_fee['Fare'] == 0)].index, inplace=True)\n",
    "print_fee_boxplot(df_removed_0_fee)\n",
    "plt.show()\n",
    "print_fee_boxplot(df_removed_0_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17a73f-10bf-4bd1-9c1a-f32a207ab4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_fee_log_pred = do_prediction(df_removed_fee, 'Survived')\n",
    "outliners_log_pred = do_prediction(no_name_DF, 'Survived')\n",
    "removed_0_fee_log_pred = do_prediction(df_removed_0_fee, 'Survived')\n",
    "\n",
    "predict_for_passengers(passengers,removed_fee_log_pred)\n",
    "predict_for_passengers(passengers,outliners_log_pred)\n",
    "predict_for_passengers(passengers,removed_0_fee_log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23831e-a0db-477b-b533-63cfb56b6dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
